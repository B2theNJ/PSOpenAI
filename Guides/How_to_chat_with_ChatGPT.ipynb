{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to chat with ChatGPT\n",
    "\n",
    "ChatGPT is powered by `gpt-3.5-turbo` and `gpt-4`, OpenAI's most advanced models.\n",
    "\n",
    "PSOpenAI PowerShell module provides `Request-ChatGPT` command for using the OpenAI API throw PowerShell friendly style.\n",
    "\n",
    "`Request-ChatGPT` take a series of messages as input, and return an AI-written message as output.\n",
    "\n",
    "This guide illustrates how to use `Request-ChatGPT` with various parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the PSOpenAI module and set API key\n",
    "\n",
    "If you set the API key to the environment variable named `OPENAI_API_KEY`. PSOpenAI commands will use it implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "Import-Module ..\\PSOpenAI.psd1\n",
    "\n",
    "# Set OpenAI API Key\n",
    "$env:OPENAI_API_KEY = '<Put your API key here>'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ask one question to ChatGPT, and get an answer\n",
    "\n",
    "`Request-ChatGPT` has some basic optional parameters:\n",
    "\n",
    "+ `-Message`: The messages to ChatGPT.\n",
    "+ `-Model`: The name of the model you want to use (e.g.: `gpt-3.5-turbo`, `gpt-4`). This is optional. If not specified, `gpt-3.5-turbo` will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32;1mid      : \u001b[0mchatcmpl-75fhjNRzdwwLz4c7DILRiGDN89Z65\n",
      "\u001b[32;1mobject  : \u001b[0mchat.completion\n",
      "\u001b[32;1mmodel   : \u001b[0mgpt-3.5-turbo-0301\n",
      "\u001b[32;1musage   : \u001b[0m@{prompt_tokens=16; completion_tokens=23; total_tokens=39}\n",
      "\u001b[32;1mchoices : \u001b[0m{@{message=; finish_reason=stop; index=0}}\n",
      "\u001b[32;1mcreated : \u001b[0m2023/04/16 4:18:27\n",
      "\u001b[32;1mMessage : \u001b[0mHi, please tell me your name.\n",
      "\u001b[32;1mAnswer  : \u001b[0m{I am an AI language model developed by OpenAI, and my creators refer to me as GPT-3.}\n",
      "\u001b[32;1mHistory : \u001b[0m{System.Collections.Specialized.OrderedDictionary, System.Collections.Specialized.Ordered\n",
      "          Dictionary}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "$Response = Request-ChatGPT -Message \"Hi, please tell me your name.\" -Model \"gpt-3.5-turbo\"\n",
    "Write-Output $Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the response object has a few fields:  \n",
    "\n",
    "+ `id`: The ID of the request\n",
    "+ `object`: The type of object returned\n",
    "+ `model`: The full name of the model used to generate the response\n",
    "+ `usage`: The number of tokens used to\n",
    "+ `choices`: a list of completion objects\n",
    "+ `created`: The timestamp of the request\n",
    "+ `Message`: The message to the ChatGPT\n",
    "+ `Answer`: a list of the response messages from ChatGPT\n",
    "+ `History`: a list of message history of past dialogues\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract just the reply with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI language model developed by OpenAI, and my creators refer to me as GPT-3.\r\n"
     ]
    }
   ],
   "source": [
    "$Response.Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiple messages with context preserved (conversation)\n",
    "\n",
    "`Request-ChatGPT` accepts past dialogs from pipeline. Additional questions can be asked while maintaining context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]: As of 2021, the population of the United States is estimated to be approximately 331 million people.\n",
      "[2]: 2021年現在、アメリカ合衆国の人口は約3億3100万人と推定されています。\n"
     ]
    }
   ],
   "source": [
    "$Response1 = Request-ChatGPT -Message \"What is the population of the United States? Please answer briefly.\"\n",
    "\"[1]: \" + $Response1.Answer\n",
    "\n",
    "$Response2 = $Response1 | Request-ChatGPT -Message \"Translate the previous answer into Japanese.\"\n",
    "\"[2]: \" + $Response2.Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System messages (Role prompt)\n",
    "\n",
    "The system message can be used to prime the assistant with different personalities or behaviors.\n",
    "\n",
    "`Request-ChatGPT` has `-RolePrompt` parameter for specifiyng system message.\n",
    "\n",
    "Be aware that the how much pay attention to the system message is depending on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Население Соединенных Штатов - около 329,5 миллионов человек.\r\n"
     ]
    }
   ],
   "source": [
    "$Response = Request-ChatGPT `\n",
    "    -Message \"What is the population of the United States? Please answer briefly.\" `\n",
    "    -RolePrompt \"Please answer in Russian.\"\n",
    "\n",
    "$Response.Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the effect of the system messages, questions asked in English were answered in Russian."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stream completions\n",
    "\n",
    "By default, when you request a completion from the OpenAI, the entire completion is generated before being sent back in a single response.\n",
    "\n",
    "If you're generating long completions, waiting for the response can take many seconds.\n",
    "\n",
    "To get responses sooner, you can 'stream' the completion as it's being generated. This allows you to start printing or processing the beginning of the completion before the full completion is finished.\n",
    "\n",
    "To stream completions, set `-Stream` switch as true.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsides\n",
    "\n",
    "Note that using stream completions, the only response you get is the response text generated, so you do not have access to any other details. For example, the number of tokens consumed by the request is no longer known, and it is no longer possible to maintain a history of past interactions using pipeline input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is an online community of knowledgeable strangers, connecting people through thoughtful conversations and insightful perspectives."
     ]
    }
   ],
   "source": [
    "Request-ChatGPT 'Describe ChatGPT in 100 charactors.' -Stream | Write-Host -NoNewline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Typical completions (no stream)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response received 3884 ms after request\n",
      "\n",
      "-------------------------\n",
      "\n",
      "2. Stream completions\n",
      "[0] Message chunk received 292 ms after request\n",
      "[1] Message chunk received 322 ms after request\n",
      "[2] Message chunk received 353 ms after request\n",
      "[3] Message chunk received 387 ms after request\n",
      "[4] Message chunk received 419 ms after request\n",
      "[5] Message chunk received 453 ms after request\n",
      "...\n",
      "Full response received 3743 ms after request\n"
     ]
    }
   ],
   "source": [
    "# How much time is saved by streaming a chat completion\n",
    "\n",
    "\"1. Typical completions (no stream)\"\n",
    "$sw1 = [System.Diagnostics.Stopwatch]::StartNew()\n",
    "$Response = Request-ChatGPT 'Describe ChatGPT in 100 words.' -Temperature 0\n",
    "$sw1.Stop()\n",
    "\"Full response received {0} ms after request\" -f $sw1.ElapsedMilliseconds\n",
    "\n",
    "\"`r`n-------------------------`r`n\"\n",
    "\n",
    "\"2. Stream completions\"\n",
    "$counter = 0\n",
    "$sw2 = [System.Diagnostics.Stopwatch]::StartNew()\n",
    "Request-ChatGPT 'Describe ChatGPT in 100 words.' -Temperature 0 -Stream | % {\n",
    "    if($counter -le 5){ \"[{1}] Message chunk received {0} ms after request\" -f $sw2.ElapsedMilliseconds, $counter }\n",
    "    if($counter -eq 6){\"...\"}\n",
    "    $counter++\n",
    "}\n",
    "$sw2.Stop()\n",
    "\"Full response received {0} ms after request\" -f $sw2.ElapsedMilliseconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical request without stream, it takes about 4 seconds to get an answer, but with stream, the time to finally get the full answer is not significantly different, but the first partial answer can be obtained in about 0.3 seconds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About output type of stream\n",
    "\n",
    "Stream output is sequentially output to the PowerShell pipeline (standard output stream). Therefore, when the stream output is saved to a variable or displayed on the console, it is not a single string, but an array of small string chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output type: System.Object[]\n",
      "Size of an array: 30\n",
      "Chat\n",
      "G\n",
      "PT\n",
      " is\n",
      " a\n",
      " free\n",
      "ChatGPT is a free online chat platform where you can talk to people from around the world on a variety of topics, and make new friends.\n"
     ]
    }
   ],
   "source": [
    "$Response = Request-ChatGPT 'Describe ChatGPT in 100 charactors.' -Stream\n",
    "\"Output type: \" + $Response.GetType().Fullname  # Array of strings\n",
    "\"Size of an array: \" + $Response.Count\n",
    "$Response[0..5]\n",
    "\n",
    "# Array of string to single string\n",
    "-join $Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to display output to the console and save it to a variable as well\n",
    "\n",
    "Stream output is simultaneously output to the information stream in addition to the standard output stream. This can be used to save to variables and display on the console at the same time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is an online chat platform where people from around the world can connect and engage in conversations about various topics.\n",
      "ChatGPT is an online chat platform where people from around the world can connect and engage in conversations about various topics.\n"
     ]
    }
   ],
   "source": [
    "Request-ChatGPT 'Describe ChatGPT in 100 charactors.' -Stream -InformationVariable Response | Write-Host -NoNewline\n",
    "\"\"\n",
    "-join $Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use with content moderation\n",
    "\n",
    "This section describes how to test messages to / from ChatGPT for violations of OpenAI's content policy. `Request-Moderation` function provides this functionality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple senario\n",
    "\n",
    "Before a message is entered to `Request-ChatGPT`, you can insert `Request-Moderation` into the pipeline. As `Request-Moderation` will output a warning message if the input text violates the content policy, specifying `-WarningAction` as `Stop` will stop processing before the message is passed on to the subsequent pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING: This content may violate the content policy. (violence)\u001b[0m\n",
      "\u001b[31;1mWrite-Warning: \u001b[0mRequest-Moderation.ps1:102\u001b[0m\n",
      "\u001b[31;1m\u001b[0m\u001b[36;1mLine |\u001b[0m\n",
      "\u001b[31;1m\u001b[0m\u001b[36;1m\u001b[36;1m 102 | \u001b[0m …             \u001b[36;1mWrite-Warning \"This content may violate the content polic\u001b[0m …\u001b[0m\n",
      "\u001b[31;1m\u001b[0m\u001b[36;1m\u001b[36;1m\u001b[0m\u001b[36;1m\u001b[0m\u001b[36;1m     | \u001b[31;1m               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n",
      "\u001b[31;1m\u001b[0m\u001b[36;1m\u001b[36;1m\u001b[0m\u001b[36;1m\u001b[0m\u001b[36;1m\u001b[31;1m\u001b[31;1m\u001b[36;1m     | \u001b[31;1mThe running command stopped because the preference variable \"WarningPreference\" or common\u001b[0m\n",
      "\u001b[31;1m\u001b[0m\u001b[36;1m\u001b[36;1m\u001b[0m\u001b[36;1m\u001b[0m\u001b[36;1m\u001b[31;1m\u001b[31;1m\u001b[36;1m\u001b[31;1m\u001b[36;1m     | \u001b[31;1mparameter is set to Stop: This content may violate the content policy. (violence)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "'I want to kill them.' | Request-Moderation -WarningAction Stop | Request-ChatGPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex senario\n",
    "\n",
    "If you want to test not only input but also output messages of the AI, or if you want to perform custom processing when a policy is violated, you will need to be a bit more  complex procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING: This content may violate the content policy. (violence)\u001b[0m\n",
      "Input message is harmful.\n",
      "I'm sorry, but as an AI language model, I can't cond\n",
      "Output message is safe.\n"
     ]
    }
   ],
   "source": [
    "$InputMessage = 'I want to kill them.'\n",
    "\n",
    "# Test the input message.\n",
    "$InputModeration = Request-Moderation -Text $InputMessage\n",
    "if($InputModeration.results[0].flagged -eq $true){\n",
    "    # Custom procedure whtn the input message violates the polocy.\n",
    "    echo 'Input message is harmful.'\n",
    "}\n",
    "else{\n",
    "    echo 'Input message is safe.'\n",
    "}\n",
    "\n",
    "# Get an answer from ChatGPT\n",
    "$Response = Request-ChatGPT -Message $InputMessage -MaxTokens 15\n",
    "echo $Response.Answer[0]\n",
    "\n",
    "# Test the output message.\n",
    "$OutputModeration = Request-Moderation -Text $Response.Answer[0]\n",
    "if($OutputModeration.results[0].flagged -eq $true){\n",
    "    # Custom procedure whtn the output message violates the polocy.\n",
    "    echo 'Output message is harmful.'\n",
    "}\n",
    "else{\n",
    "    echo 'Output message is safe.'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Miscellaneous options\n",
    "\n",
    "`Request-ChatGPT` has some optional parameters.\n",
    "\n",
    "+ `-Model`\n",
    "+ `-Name`\n",
    "+ `-RolePrompt`\n",
    "+ `-Temperature`\n",
    "+ `-TopP`\n",
    "+ `-NumberOfAnswers`\n",
    "+ `-StopSequence`\n",
    "+ `-MaxTokens`\n",
    "+ `-PresencePenalty`\n",
    "+ `-FrequencyPenalty`\n",
    "+ `-LogitBias`\n",
    "+ `-User`\n",
    "+ `-TimeoutSec`\n",
    "+ `-MaxRetryCount`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the response deterministic\n",
    "\n",
    "If a small value such as `0` or `0.1` is specified for the `-Temperature` parameter, the response will be definitive. On the other hand, if a large value such as `0.8` is specified, the response will be random even if the same message is entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sophia.\n",
      "Sophia\n",
      "Sophia.\n",
      "Sophia.\n",
      "Sophia.\n"
     ]
    }
   ],
   "source": [
    "$Message = 'Please output one female name, as appropriate.'\n",
    "# Ask same question 5 times.\n",
    "(1..5) | % {\n",
    "    Request-ChatGPT -Message $Message -Temperature 0.1 | select -ExpandProperty Answer\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a small value was specified for temperature, the same question can be asked repeatedly and get almost same answers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit maximum length of output\n",
    "\n",
    "Specifying the `-MaxTokens` parameter avoids unintentionally consuming too many tokens by generating excessively long responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trees sway gently in the breeze\n",
      "A symphony of rustling leaves\n",
      "The sun sets over\r\n"
     ]
    }
   ],
   "source": [
    "$Response = Request-ChatGPT -Message \"Write a poem of about 200 words.\" -MaxTokens 20\n",
    "$Response.Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A message that is expected to be quite long was used, but because a small value was specified for `-MaxTokens`, the output was terminated in the middle of the message."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate specific words\n",
    "\n",
    "`-LogitBias` can be used to increase or decrease the likelihood that a particular word (token) will be included in a response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let ChatGPT introduce itself without using the word \"AI\".\n",
    "\n",
    "First, use the `ConvertTo-Token` command to find the token ID corresponding to the word \"AI\". It may be necessary to also find token IDs for some derived words to ensure that the targeted word is eliminated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15836\n",
      "15592\n",
      "70767\n",
      "2192\n"
     ]
    }
   ],
   "source": [
    "$TargetWords = ('AI', ' AI', 'Ai', 'ai')\n",
    "$TargetWords | ConvertTo-Token -Model 'gpt-3.5-turbo'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a set of these tokens and values indicating the likelihood that these tokens will be used are created and specified in the `-LogitBias` parameter.\n",
    "\n",
    "In this case, we specify a minimum value of `-100` to minimize the likelihood that the tokens will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an artificial intelligence language model created by OpenAIGPT.\r\n"
     ]
    }
   ],
   "source": [
    "$BiasMap = @{\n",
    "    15836 = -100\n",
    "    15592 = -100\n",
    "    70767 = -100\n",
    "    2192  = -100\n",
    "}\n",
    "\n",
    "$Response = Request-ChatGPT -Message 'Please introduce yourself in about 50 characters.' -LogitBias $BiasMap -Temperature 0\n",
    "$Response.Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though it reduced the likelihood of the word \"AI\" being included in the answer, but unfortunately, the word \"OpenAIGPT\" is included.\n",
    "\n",
    "The word \"OpenAIGPT\" breaks down into four tokens:\n",
    "+ `Open` : 5109\n",
    "+ `A` : 32\n",
    "+ `IG` : 1953\n",
    "+ `PT` : 2898\n",
    "\n",
    "Eliminating the token ID of 32 would eliminate the alphabet \"A\" and thus reduce the likelihood of getting a proper answer.\n",
    "\n",
    "As such, manipulation by `-LogitBias` may not always work as expected.\n",
    "\n",
    "Therefore, it may be better to simply devise a prompt and give instructions to the model to obtain an appropriate response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an intelligent virtual assistant here to assist you.\r\n"
     ]
    }
   ],
   "source": [
    "$Response = Request-ChatGPT `\n",
    "    -Message 'Please introduce yourself in about 50 characters. But NEVER use the word \"AI\".' `\n",
    "    -Temperature 0\n",
    "$Response.Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [],
      "languageName": "pwsh",
      "name": "pwsh"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
